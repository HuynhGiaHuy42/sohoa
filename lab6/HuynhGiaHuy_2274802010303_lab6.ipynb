{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 120\n",
      "tensor([0, 1, 2]) tensor([40, 41, 39])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#\n",
    "df=pd.read_csv('Iris.csv')\n",
    "df.head()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le=LabelEncoder()\n",
    "X=df.drop(columns=['Species'],axis=1).values    \n",
    "y=le.fit_transform(df['Species'].values)\n",
    "\n",
    "#chia dữ liệu với test size=0.2\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train=torch.FloatTensor(X_train)\n",
    "X_test=torch.FloatTensor(X_test)\n",
    "y_train=torch.LongTensor(y_train).reshape(-1,1)\n",
    "y_test=torch.LongTensor(y_test).reshape(-1,1)\n",
    "\n",
    "print(f'train size {len(y_train)}')\n",
    "labels,counts=y_train.unique(return_counts=True)\n",
    "print(labels,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "\n",
    "#Sử dụng GPU và CuDa\n",
    "torch.cuda.current_device\n",
    "\n",
    "\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "\n",
    "#Trả về mức sử dụng bộ nhớ gpu hiện tại theo tensor tính bằng byte cho thiết bị\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tính đạo hàm bằng pytorch\n",
    "\n",
    "#cho y= 2x^4 + x^3 + 3x^2 + 5x + 1\n",
    "\n",
    "#tính y'\n",
    "\n",
    "import torch\n",
    "\n",
    "x=torch.tensor(2.0,requires_grad=True)\n",
    "print(x)\n",
    "print(x.grad)\n",
    "#Định nghĩa hàm\n",
    "\n",
    "y=2*x**4 + x**3 + 3*x**2 + 5*x + 1\n",
    "print(y)\n",
    "y.grad_fn\n",
    "\n",
    "#thực hiện truyền ngược và tính toán các gradient\n",
    "y.backward()\n",
    "# Kết quả đạo hàm \n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ dốc của hàm số tại x = 2.0 là: 1161.0\n"
     ]
    }
   ],
   "source": [
    "#bài tập \n",
    "#cho y=5x^6+3x^3+2x^1+x+2x+5x^4+1\n",
    "\n",
    "#cho biết độ dốc của đa thức trên tại điểm nào \n",
    "\n",
    "import torch\n",
    "\n",
    "# Khai báo biến x với yêu cầu tính gradient\n",
    "x = torch.tensor(2.0, requires_grad=True)  # Có thể thay 2.0 bằng bất kỳ giá trị nào để kiểm tra độ dốc tại điểm đó\n",
    "\n",
    "# Định nghĩa hàm số\n",
    "y = 5*x**6 + 3*x**3 + 2*x**1 + x +2*x + 5*x**4 +1\n",
    "\n",
    "# Tính gradient\n",
    "y.backward()\n",
    "\n",
    "# Kết quả đạo hàm tại x\n",
    "print(f\"Độ dốc của hàm số tại x = {x.item()} là: {x.grad.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BTVN 2:\n",
    "#Tạo 1 tập dữ liệu giả lập với x là số giờ học ( ngẫu nhiên từ 1-10) và y là số điểm được tính theo công thức = 3x +5 + noise \n",
    "#Với noise là một giá trị ngẫu nhiên nhỏ\n",
    "# Khởi tạo tham số w và b ngẫu nhiên với requires_grad = True   \n",
    "# Tính MSE\n",
    "# Tính gradient\n",
    "# Cập nhật tham số w và b bằng gradient descent với Learning rate alpha = 0.01\n",
    "# Lặp lại quá trình trên trong 100 vòng lặp và quan sát sự hội tụ của mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Loss: 43.1895 | w: 3.3279 | b: 0.6265\n",
      "[Epoch 10] Loss: 3.9263 | w: 3.6400 | b: 0.8250\n",
      "[Epoch 20] Loss: 3.6044 | w: 3.6129 | b: 1.0018\n",
      "[Epoch 30] Loss: 3.3094 | w: 3.5869 | b: 1.1710\n",
      "[Epoch 40] Loss: 3.0392 | w: 3.5620 | b: 1.3329\n",
      "[Epoch 50] Loss: 2.7916 | w: 3.5382 | b: 1.4879\n",
      "[Epoch 60] Loss: 2.5648 | w: 3.5155 | b: 1.6362\n",
      "[Epoch 70] Loss: 2.3570 | w: 3.4937 | b: 1.7782\n",
      "[Epoch 80] Loss: 2.1667 | w: 3.4728 | b: 1.9142\n",
      "[Epoch 90] Loss: 1.9923 | w: 3.4528 | b: 2.0442\n",
      "[Epoch 100] Loss: 1.8325 | w: 3.4337 | b: 2.1688\n",
      "\n",
      "Huấn luyện hoàn tất!\n",
      "Giá trị cuối cùng: w = 3.4337, b = 2.1688\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# Đặt seed để đảm bảo kết quả tái lập\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Số lượng mẫu dữ liệu\n",
    "n_samples = 100\n",
    "\n",
    "# Tạo dữ liệu x ngẫu nhiên từ 1 đến 10 và noise nhỏ\n",
    "x_list = [random.randint(1, 10) for _ in range(n_samples)]\n",
    "noise_list = [random.uniform(-0.5, 0.5) for _ in range(n_samples)]\n",
    "\n",
    "# Chuyển đổi sang tensor của PyTorch\n",
    "x = torch.tensor(x_list, dtype=torch.float32)\n",
    "noise = torch.tensor(noise_list, dtype=torch.float32)\n",
    "\n",
    "# Tính giá trị y dựa theo công thức y = 3x + 5 + noise\n",
    "y = 3 * x + 5 + noise\n",
    "\n",
    "# Khởi tạo tham số w và b ngẫu nhiên, yêu cầu tính gradient\n",
    "w = torch.randn(1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# Thiết lập learning rate và số vòng lặp\n",
    "alpha = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Bắt đầu vòng lặp Gradient Descent\n",
    "for epoch in range(epochs):\n",
    "    # Dự đoán giá trị y\n",
    "    y_pred = w * x + b\n",
    "\n",
    "    # Tính toán hàm mất mát (MSE)\n",
    "    loss = torch.mean((y_pred - y) ** 2)\n",
    "\n",
    "    # Reset gradient trước khi tính toán lại\n",
    "    if w.grad is not None:\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "    # Tính toán gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # Cập nhật giá trị w và b bằng công thức của Gradient Descent\n",
    "    with torch.no_grad():\n",
    "        w -= alpha * w.grad\n",
    "        b -= alpha * b.grad\n",
    "\n",
    "    # Hiển thị thông tin mỗi 10 vòng lặp\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 1:\n",
    "        print(f\"[Epoch {epoch+1}] Loss: {loss.item():.4f} | w: {w.item():.4f} | b: {b.item():.4f}\")\n",
    "\n",
    "print(\"\\nHuấn luyện hoàn tất!\")\n",
    "print(f\"Giá trị cuối cùng: w = {w.item():.4f}, b = {b.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
